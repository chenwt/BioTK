#!/usr/bin/env python

"""
Both "gold" and "predicted" are two-column, tab-delimited files with:
- First column: row/datum ID
- Second column: true or predicted value (either categorical or continuous)

Caveats:
- Ignores predictions from <predicted> whose row labels are not in <gold>
  (a prediction that should be null should be blank in <gold>)
- When no prediction is specified for a gold label, either maximum likelihood
  is used (categorical) or mean (regression)
"""

import argparse
import sys

import numpy as np
import pandas as pd
from sklearn import metrics

def regression(y, yh, **kwargs):
    try:
        y = y.astype(np.float64)
        yh = yh.astype(np.float64)
    except ValueError as e:
        msg = " ".join("""
        Regression problem was specified, 
        but the second column of either the gold 
        or predicted file contains a non-numeric 
        value.""".split())
        e.args = [msg]
        raise e
    mu = y.mean()
    y, yh = y.align(yh, join="left", fill_value=mu)

    data = [getattr(metrics, k)(y,yh)
            for k in 
            [   "explained_variance_score",
                "mean_absolute_error",
                "mean_squared_error",
                "r2_score"]]
    return pd.Series(data,
            index=["Explained Variance",
                "MAD", "MSE", "R-Squared"])

def classification(y, yh, report=False):
    most_common = y.value_counts().index[0]
    y, yh = y.align(yh, join="left", fill_value=most_common)
    y = pd.Categorical.from_array(y)
    yh = pd.Categorical.from_array(yh)

    if report:
        return metrics.classification_report(y, yh)
    
    y = y.labels
    yh = yh.labels
    methods = [
        "f1_score",
        "average_precision_score",
        "roc_auc_score",
        "log_loss"
    ]
    index = [
        "F-Measure",
        "AP",
        "AUC",
        "Log Loss"
    ]
    data = [getattr(metrics, k)(y, yh)
            for k in methods]
    return pd.Series(data, index=index)

def main(args):
    p = argparse.ArgumentParser()
    p.add_argument("gold", type=argparse.FileType("r"))
    p.add_argument("predicted", type=argparse.FileType("r"))
    p.add_argument("--regression", "-r", action="store_true",
            help="Indicates this is a regression problem, altering the metrics used.")
    p.add_argument("--report", "-e", action="store_true",
            help="Display a detailed (non-tabular) classification report. Ignored for regression.")
    args = p.parse_args(args)

    read = lambda h: pd.read_table(h, header=None, index_col=0)\
            .iloc[:,0].dropna()
    y = read(args.gold)
    yh = read(args.predicted)

    if args.regression:
        fn = regression
    else:
        fn = classification

    try:
        rs = fn(y,yh,report=args.report)
        if isinstance(rs, str):
            print(rs, end="")
        else:
            rs.to_csv(sys.stdout, sep="\t")
    finally:
        args.gold.close()
        args.predicted.close()

if __name__ == "__main__":
    main(sys.argv[1:])
