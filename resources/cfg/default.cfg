[BioTK]

#########
# Logging
#########

# How much logging information do we want?
# Valid options are, from least to most information: 
#   CRITICAL, ERROR, WARNING, INFO, DEBUG, NOTSET
log.level = DEBUG

# The logging output format.
# For available variables, see:
# https://docs.python.org/3.4/library/logging.html#logrecord-attributes
# FIXME: something wrong with the escaping here
# log.format = %(asctime)s - %(name)s - %(levelname)s - %(message)s

# Send logging information to the console?
log.console = True

# Send logging information to the UNIX syslog?
log.syslog = False

# Write logging information to a file at this path
# (If not provided, will be ignored)
log.file =
# log.file = ./BioTK.log

##############
# File caching
##############

# Downloaded files and some temporary computations are stored
# in a cache directory.

# Base directory for cached data
cache.dir = ~/.cache/BioTK

#######
# Redis
#######

# Redis is used caching results from the job queue and caching results 
# from certain function calls. These functionalities use different 
# databases within the same Redis instance.

redis.host = localhost
redis.port = 6379
redis.result_store.index = 0
redis.cache.index = 1
redis.ui_cache.index = 2

########
# Celery
########

celery.cfg.enable_utc = True
celery.cfg.timezone = US/Chicago
celery.cfg.accept_content = pickle,msgpack
celery.broker.url = "amqp://"
celery.queue = default

##########
# Database
##########

# Global PostgreSQL database containing BioTK data. This database stores gene 
# names, taxonomy data, gene locus mapping, etc.

db.host = wren
db.port = 5432
db.name = BioTK
db.user = BioTK

# Whether to download data for empty tables and populate the DB
# (will cause slow startup the first time the DB is populated,
#   and requires a network connection)
db.auto_populate = True

##########
# Datasets
##########

# The root folder for static or mostly-static datasets. For individual 
# datasets, if a relative path is given, it will be interpreted relative 
# to this directory.
data.root.dir = /data/public

# Biomedical ontologies to import as "terms"
data.ontologies = GO,BTO,EFO,MGED

# This is the base directory for RNA-seq data in BigWig format.
# The directory structure is:
#   /{ncbi_taxon_id}/{genome_build}/*.bw, where each BigWig file
#   name (minus the extension) will be the ID assigned to that sample
#   for the various functions using that data.
data.rnaseq.dir = Sequencing/RNA

###############
# NCBI datasets
###############

# The root directory for all NCBI datasets (relative to the 'data.root.dir
# if it is a relative path).
# All other NCBI datasets will be interpreted relative to this
# directory if they are relative paths.
ncbi.root.dir = ncbi

# NCBI Gene Expression Omnibus data.
ncbi.geo.dir = geo

# NCBI MEDLINE data (contains titles, abstracts, etc.)
ncbi.medline.dir = medline
# Downloading MEDLINE data requires a site license from NCBI, and they 
# restrict access to license holders by IP, so if you don't have a license,
# you can't download it. Set this parameter to True if you have a license
# and want to use MEDLINE data (required for text mining modules).
ncbi.medline.enabled = False

###############
# UCSC datasets
###############

# Flat files will be stored in this directory (relative to
# the 'data.root.dir' if it is a relative path).
ucsc.root.dir = UCSC

# A comma-separated list of all the UCSC genome builds that are enabled.
# This primarily affects what flat files will be downloaded.
ucsc.genomes = hg19,mm9

# UCSC annotation tracks are stored in a MySQL database, which
# can be used for querying overlapping regions and finding other
# metadata about, e.g., transcripts.
# It is assumed that the database name for each genome assembly
# is that assembly's name (e.g., 'hg19').
ucsc.mysql.host = genome-mysql.cse.ucsc.edu
ucsc.mysql.user = genomep
ucsc.mysql.password = password

# If this parameter is set to True, then on startup, flat files
# for each database specified by the 'ucsc.genomes' parameter
# will be synchronized from UCSC (if necessary) to folders under the 
# 'ucsc.root.dir', then these files will be imported into the UCSC MySQL
# database.
# This requires write access the 'ucsc.mysql.host' database host.
# Caution, this can take a very long time (hours or days, depending
# on your internet connection). The intended use is to make a local
# mirror for heavy queries of UCSC tracks.
ucsc.mysql.auto_populate = False
