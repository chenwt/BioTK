#!/usr/bin/env bash

# Download multiple URLs simultaneously

# TODO: Use aria2c if available, and/or other methods for detecting optimal number of concurrent connections
# TODO: Detect URLs that can use Aspera, and use that when available (one at a time)


usage() {
    cat <<EOF
Download multiple URLs simultaneously.

USAGE: cat urls | multiget [ -P <prefix> ] 

Options:
    -j : Number of simultaneous downloads.
    -P : Directory to output downloaded files.
EOF
    exit $1
}

get_host() {
    python <(cat <<EOF 
from urllib.parse import urlparse
url = urlparse('$1')
print(url.netloc if url.netloc else url.path)
EOF
)
}

outdir=$(pwd)
n_jobs=4
while getopts P:j: opt; do
    case $opt in
        P) outdir="$OPTARG" ;;
        j) n_jobs="$OPTARG" ;;
        ?) usage 1 ;;
    esac
done

while read url; do
    sem --id multiget -j $n_jobs wget -nc -P $outdir $url
done
sem --wait --id multiget
