#!/usr/bin/env python3

import argparse
import sys

import numpy as np
import pandas as pd

if __name__ == "__main__":
    p = argparse.ArgumentParser()
    p.add_argument("-n", default=20, type=int,
            help="Number of top correlated columns to print.")
    p.add_argument("--all", "-a", action="store_true",
            help="Print entire correlation matrix")
    p.add_argument("--significant-digits", "-d", type=int, default=3)
    # --method: pearson/spearman/kendall
    args = p.parse_args()
    float_format = "%0." + str(args.significant_digits) + "f"

    X = pd.read_table(sys.stdin, index_col=0, sep="\t")
    X = (X - X.mean() / X.std())

    index = X.index
    columns = X.columns
    nc = len(columns)
    nr = len(index)
    X = np.array(X)
    mask = ~np.isnan(X)

    if args.all:
        print("", *columns, sep="\t")

    n = min(args.n, nr - 1)
    for j,c in enumerate(columns):
        cor = np.zeros(nc)
        cor[:] = np.nan
        for jj in range(nc):
            ix = mask[:,j] & mask[:,jj]
            if ix.sum() < 2:
                continue
            cor[jj] = np.dot(X[ix,j],X[ix,jj]) / (ix.sum() - 1)
        # FIXME: this is a hack meaning the correlation values will not be exactly right
        # really the standardization should be done with each individual mask 
        # but that would be much slower and probably not much more accurate
        cor = np.maximum(np.minimum(1, cor), -1)
        if args.all:
            print(c, *[float_format % x for x in cor], sep="\t")
        else:
            cor = pd.Series(cor, index=columns)
            cor[c] = 100
            cor = cor.dropna()
            cor.sort(ascending=False)
            print(c, *cor.index[:n], sep="\t")
