#!/usr/bin/env python3

import sys

import click
import pandas as pd
import numpy as np
from sklearn.linear_model import LogisticRegression
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import roc_auc_score
from sklearn.cross_validation import cross_val_score
from sklearn.preprocessing import Imputer

from BioTK import mmat

@click.group()
def cli():
    pass

RUN_VW = """
"""

@cli.command()
@click.argument("matrix")
def multilabel(matrix):
    """
    Perform multilabel prediction and validation.

    Input:

        stdin: a two or three-column sparse matrix
           of training labels, with the following:
             column 1: sample ID
             column 2: label name
             column 3 (optional): the value. 
               for regression: any real number
               for binary: 
                 positive: 1
                 negative: -1 
                 unknown/to be predicted: 0
               for multiclass: (not implemented)
               
        matrix: a MMAT format matrix where rows are 
           samples and columns are predictors (e.g., genes)

    Notes:
    - regression or binary classification will be detected
        by the data type in the labels file (on stdin)
    """

    Y = pd.read_csv(sys.stdin, sep="\t", header=None)
    assert Y.shape[1] in (2,3)
    if Y.shape[1] == 2:
        Y["value"] = 1

    generate_negative = False
    if (Y["value"] == 1).all():
        binary = True
        generate_negative = True
    elif Y.dtype == float:
        binary = False
    else:
        assert False, "not implemented to provide explicit positive/negative labels"
    assert binary

    Y = Y.pivot(*Y.columns).dropna(axis=0, thresh=1)
    if generate_negative:
        for j in range(Y.shape[1]):
            y = Y.iloc[:,j]
            empty = np.nonzero(np.isnan(y))[0]
            np.random.shuffle(empty)
            n = (y == 1).sum()
            for i in empty[:n]:
                Y.iloc[i,j] = -1

    Y = Y.to_sparse(fill_value=np.nan)
    X = mmat.MMAT(matrix)
    x_ix = set(X.index)
    assert binary

    np.random.seed(100)
    ix = np.random.choice(X.index, size=500, replace=False)
    mu = X.loc[ix,:].mean(axis=1).dropna()

    score_fn = "roc_auc"

    print("Label", "N", "AUC", "AUC SD", sep="\t", file=sys.stderr)
    print("", *X.index, sep="\t")
    for label in Y.columns:
        sys.stdout.flush()
        sys.stderr.flush()
        y = Y[label]
        if binary:
            y = y.ix[y.isin((-1,1))]
        else:
            # regression, todo
            pass
        ix = list(set(y.index) & x_ix)

        x_tr = X.loc[ix,mu.index].to_frame()
        y = y.to_dense()[ix]
        for r in x_tr.index:
            ix = x_tr.loc[r,:].isnull()
            x_tr.loc[r,ix] = mu[ix]

        n = len(y)
        k = min(y.value_counts().min(), 10)
        if n < 10 or len(set(y)) == 1 or k <= 3:
            continue

        vc = y.value_counts()
        weights = None
        if generate_negative:
            weights = {1:1/vc[1],-1:1/(X.shape[1]-vc[1])}
        y = np.array(y)

        model = RandomForestClassifier(class_weight=weights)
        scores = cross_val_score(model, x_tr, y, scoring=score_fn,
                cv=k, njobs=-1)
        print(label, n, scores.mean(), scores.std(), sep="\t",
                file=sys.stderr)
        model.fit(x_tr, y)
        pos_ix = list(model.classes_).index(1)
        y_hat = []
        for i in X.index:
            x = np.array(X.loc[i,mu.index])
            ix = np.isnan(x)
            x[ix] = mu[ix]
            yh = model.predict_log_proba(x)[:,pos_ix]
            y_hat.append("%0.3f" % yh)
        print(label, *y_hat, sep="\t")

if __name__ == "__main__":
    cli()
