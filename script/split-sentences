#!/usr/bin/env python3

import sys

from nltk.tokenize import sent_tokenize

for line in sys.stdin:
    fields = line.rstrip("\n").split("\t")
    i = 0
    for text in fields[1:]:
        for sentence in sent_tokenize(text):
            if len(sentence) > 10:
                print(fields[0], i, sentence.rstrip("."), sep="\t")
                i += 1
